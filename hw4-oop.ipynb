{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classifier import classifier\n",
    "import numpy as np\n",
    "\n",
    "class knn(classifier):\n",
    "\n",
    "    def __init__(self, train_X, train_Labels):\n",
    "        self.X = train_X\n",
    "        self.Y = train_Labels\n",
    "        self.new_Y = []\n",
    "        self.kn = None\n",
    "\n",
    "    def fit(self, kn):        \n",
    "        self.kn = kn\n",
    "        for i in range(len(self.X)):\n",
    "            label = self.getLabel(self.X.iloc[i])\n",
    "            self.new_Y.append(label)\n",
    "        return self.new_Y\n",
    "     \n",
    "    def calAcc(self):\n",
    "        l1 = len(self.Y)\n",
    "        l2 = 0\n",
    "        for i in range(l1):\n",
    "            if self.Y[i] == self.new_Y[i]:\n",
    "                l2+=1\n",
    "        return l2/l1\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        hyp_Y = []\n",
    "        for i in range(len(test_X)):\n",
    "            label = self.getLabel(test_X.iloc[i])\n",
    "            hyp_Y.append(label)\n",
    "        return hyp_Y\n",
    "    \n",
    "    def predictOne(self, x):\n",
    "        return self.getLabel(x)    \n",
    "   \n",
    "    def getAllDists(self,x): \n",
    "        dlist = self.calDist(x) \n",
    "        index = np.argsort(dlist) \n",
    "        dlist.sort()\n",
    "        return dlist, index\n",
    "\n",
    "    def calDist(self, x):\n",
    "        x = np.array(x)\n",
    "        arr = np.array(self.X)\n",
    "        ds = np.sum((x - arr)**2, axis=1)    \n",
    "        return np.sqrt(ds)\n",
    "\n",
    "\n",
    "    def getLabel(self,x):\n",
    "        dlist, index = self.getAllDists(x) \n",
    "        avg = 0.0 \n",
    "        for i in range(self.kn): \n",
    "            avg = avg + self.Y[index[i]] \n",
    "        avg = round(avg / self.kn)\n",
    "        return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting all the arff files from the current directory\n",
    "file = 'PhishingData.arff'\n",
    "\n",
    "# Function for converting arff list to csv list\n",
    "def toCsv(content):\n",
    "    data = False\n",
    "    header = \"\"\n",
    "    newContent = []\n",
    "    for line in content:\n",
    "        if not data:\n",
    "            if \"@attribute\" in line:\n",
    "                attri = line.split()\n",
    "                columnName = attri[attri.index(\"@attribute\")+1]\n",
    "                header = header + columnName + \",\"\n",
    "            elif \"@data\" in line:\n",
    "                data = True\n",
    "                header = header[:-1]\n",
    "                header += '\\n'\n",
    "                newContent.append(header)\n",
    "        else:\n",
    "            newContent.append(line)\n",
    "    return newContent\n",
    "\n",
    "# Main loop for reading and writing files\n",
    "\n",
    "with open(file , \"r\") as inFile:\n",
    "    content = inFile.readlines()\n",
    "    name,ext = os.path.splitext(inFile.name)\n",
    "    new = toCsv(content)\n",
    "    newFile = name + \".csv\"\n",
    "    with open(newFile, \"w\") as outFile:\n",
    "        outFile.writelines(new)\n",
    "        \n",
    "df = pd.read_csv(newFile) #legitimate(1), suspicious(0) or phishy(-1) based on whether the site contains pop-up windows\n",
    "train_X = df.iloc[:,:-1]\n",
    "train_Labels = df.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8492239467849224\n",
      "[-0.0, 1.0, 1.0, -0.0, 1.0, 1.0, -0.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 0.0, 0.0, -1.0, -0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -0.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 1.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 1.0, 0.0, -0.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 0.0, -0.0, -1.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 0.0, -1.0, -1.0, 1.0, 0.0, 0.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -0.0, 0.0, -1.0, -1.0, 1.0, -1.0, 1.0, -0.0, -0.0, 1.0, 1.0, 0.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -0.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 1.0, -1.0, 1.0, 1.0, -0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, -0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 1.0, -1.0, -1.0, -1.0, -0.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 1.0, -1.0, -0.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 0.0, -0.0, 1.0, -1.0, -1.0, 1.0, -1.0, -0.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -0.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -0.0, 0.0, -1.0, 1.0, -0.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -0.0, 0.0, -1.0, -1.0, 1.0, -1.0, 1.0, -0.0, -0.0, 1.0, 1.0, -0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 0.0, 1.0, -0.0, 1.0, -0.0, 1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -0.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 1.0, -1.0, -0.0, -0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 1.0, -1.0, 0.0, -1.0, -1.0, -0.0, 1.0, 1.0, -1.0, 0.0, 1.0, -1.0, 1.0, 0.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -0.0, -1.0, -1.0, 1.0, -1.0, -0.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -0.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -0.0, 1.0, -1.0, 1.0, -0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 0.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -0.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0, -1.0, 1.0, 1.0, 1.0, -0.0, 1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -0.0, 1.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -0.0, -0.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -0.0, -1.0, -1.0, 1.0, 1.0, 0.0, 1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -0.0, 1.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 1.0, -0.0, -1.0, -1.0, -1.0, 0.0, 1.0, 1.0, -0.0, -1.0, -1.0, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 1.0, -0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.0, 1.0, 1.0, 0.0, -1.0, -1.0, 0.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -0.0, -1.0, -0.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -0.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.0, 1.0, 1.0, 0.0, 1.0, 0.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -0.0, 1.0, -1.0, 0.0, -0.0, 1.0, -0.0, -0.0, -1.0, -0.0, 1.0, 1.0, 0.0, -1.0, 1.0, 1.0, -0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -0.0, 1.0, -1.0, 1.0, -1.0, -0.0, 1.0, -1.0, -0.0, 0.0, 1.0, 0.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, -1.0, 1.0, 0.0, 1.0, -1.0, -1.0, 1.0, -0.0, 1.0, -1.0, 1.0, -0.0, -1.0, -1.0, -1.0, 1.0, -0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0, -1.0, 1.0, 1.0, -1.0, 0.0, -1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 0.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, 1.0, -1.0, -0.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 1.0, -1.0, -0.0, -1.0, -1.0, -1.0, 1.0, -0.0, -1.0, -1.0, -0.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 1.0, -1.0, 1.0, 1.0, -0.0, -1.0, -1.0, -0.0, 1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, -1.0, 1.0, 0.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.0, -1.0, 1.0, 0.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 0.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, -0.0, 1.0, 1.0, 1.0, -0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 1.0, 1.0, -0.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 0.0, -0.0, -1.0, 1.0, 0.0, 1.0, -0.0, 1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 1.0, 1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 1.0, 0.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -0.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 0.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, -0.0, 1.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 1.0, -0.0, -1.0, 1.0, -1.0, 1.0, 0.0, -1.0, 1.0, -0.0, 1.0, 1.0, 1.0, -0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -0.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 0.0, -0.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0, -1.0, -0.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, -0.0, -1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, -1.0, 0.0, 1.0, 1.0, -0.0, 1.0, -1.0, 1.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 0.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -0.0, -0.0, 0.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 0.0, 1.0, -0.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, -1.0, -0.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 0.0, -0.0, -1.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -0.0, -1.0, -0.0, 0.0, 1.0, -1.0, 1.0, 1.0, -1.0, -0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 1.0, 1.0, 0.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, -1.0, -1.0, 1.0, -1.0, 1.0, 0.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "train = knn(train_X, train_Labels)\n",
    "train.fit(5)\n",
    "print(train.calAcc())\n",
    "test = 225\n",
    "newY = train.predict(train_X)\n",
    "print(newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
